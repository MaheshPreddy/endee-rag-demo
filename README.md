# Endee RAG Demo: Retrieval-Augmented Generation with Vector Search

A production-ready **Retrieval-Augmented Generation (RAG)** demo using [Endee](https://github.com/endee-io/endee), a high-performance open-source vector database. This project demonstrates semantic search, vector-based document retrieval, and LLM-augmented question answering.

**Key Features:**

- ğŸš€ FastAPI server with REST endpoints for ingestion and RAG queries
- ğŸ§  Integration with Endee vector database (Python SDK + HTTP adapter)
- ğŸ” Semantic search using OpenAI embeddings
- ğŸ“š Retrieval-Augmented Generation with GPT-4o
- ğŸ“¦ In-memory fallback for local development
- ğŸ§ª Unit tests and CI/CD pipeline (GitHub Actions)
- ğŸ³ Docker-ready (docker-compose config included)

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â”‚  Query      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FastAPI Server (app/main.py)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  /ingest  â”€â”€â–º Embedding â”€â”€â–º Vector DB  â”‚
â”‚  /query   â”€â”€â–º Embedding â”€â”€â–º Retrieve   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
       â”‚                               â”‚
       â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI Embeddingsâ”‚         â”‚  Endee Vector DB    â”‚
â”‚ (text-embedding) â”‚         â”‚  (HNSW index)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â–³
                          Python SDK or HTTP
                                      â”‚
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚  LLM (GPT-4o)   â”‚
                             â”‚  + Retrieved    â”‚
                             â”‚  Context â”€â”€â–º RAGâ”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Prerequisites

- **Python 3.9+**
- **OpenAI API Key** (for embeddings and LLM)
- **Endee** (Python SDK, or HTTP endpoint)

### 1. Clone and Install

```bash
# Clone the repository
git clone https://github.com/<your-username>/endee-rag-demo.git
cd endee-rag-demo

# Create virtual environment
python -m venv .venv
source .venv/bin/activate    # macOS/Linux
# OR on Windows PowerShell:
.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

Create a `.env` file in the project root:

```env
# Required: OpenAI API key
OPENAI_API_KEY=sk-...

# Optional: Endee vector database configuration
# If using Endee HTTP API (via docker-compose or remote):
ENDEE_BASE_URL=http://localhost:8000
ENDEE_API_KEY=              # Optional bearer token
ENDEE_COLLECTION=docs       # Optional collection name

# Optional: FastAPI configuration
API_BASE_URL=http://localhost:8000
```

### 3. Run Endee (Option A: Docker)

```bash
# Start Endee via docker-compose
docker-compose up -d

# Verify it's running
curl http://localhost:8080
```

Or visit the dashboard: http://localhost:8080

### 4. Run the FastAPI Server

```bash
# In a separate terminal, with .venv activated
uvicorn app.main:app --reload

# Server will be available at http://localhost:8000
```

### 5. Try the Demo

```bash
# In a third terminal, run the demo script
python examples/rag_demo.py
```

This will:

1. Ingest sample documents about Python and ML
2. Query the system with real questions
3. Show retrieved documents and AI-generated answers

## API Endpoints

### `/ingest` (POST)

Ingest a document and create its embedding.

**Request:**

```json
{
  "id": "doc_1",
  "text": "This is a sample document about Python."
}
```

**Response:**

```json
{
  "status": "ingested",
  "id": "doc_1"
}
```

### `/query` (POST)

Query the vector store and generate an answer using the retrieved context.

**Request:**

```json
{
  "query": "What is Python?",
  "top_k": 3
}
```

**Response:**

```json
{
  "answer": "Python is a high-level programming language known for...",
  "retrieved": [
    {
      "id": "doc_python_intro",
      "score": 0.95,
      "metadata": {
        "text": "Python is a high-level..."
      }
    }
  ]
}
```

## Vector Store Adapters

The project includes two vector store implementations:

### 1. Endee Python SDK (Preferred)

Auto-detects and uses the Endee Python SDK if installed:

```python
from app.vector_store import EndeeVectorStore
store = EndeeVectorStore(collection="docs")
```

### 2. Endee HTTP Adapter (Fallback)

Makes HTTP requests to an Endee server:

```python
from app.vector_store import EndeeVectorStore
store = EndeeVectorStore(base_url="http://localhost:8000", collection="docs")
```

### 3. In-Memory Store (Testing)

Simple in-memory vector store for local development:

```python
from app.vector_store import InMemoryVectorStore
store = InMemoryVectorStore()
```

## Integrating Your Forked Endee

To use your own fork of Endee:

1. **Fork** the Endee repository: https://github.com/endee-io/endee
2. **Install your fork locally:**

   ```bash
   # Option A: Install from your GitHub fork
   pip install git+https://github.com/<your-username>/endee.git

   # Option B: Install from local source
   cd ~/your-fork-location
   pip install -e .
   ```

3. **Configure in `.env`:**
   ```bash
   ENDEE_BASE_URL=http://localhost:8000  # Your Endee server
   ENDEE_COLLECTION=docs
   ```
4. **The adapter will automatically use your SDK** when available.

## Project Structure

```
endee-rag-demo/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                 # Environment variable template
â”œâ”€â”€ docker-compose.yml           # Docker setup for Endee
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # FastAPI server (routes)
â”‚   â””â”€â”€ vector_store.py          # Vector DB adapters
â”‚
â”œâ”€â”€ samples/
â”‚   â””â”€â”€ dataset.py               # Sample documents for testing
â”‚
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ rag_demo.py              # End-to-end demo script
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_vector_store.py     # Unit tests
â”‚
â””â”€â”€ .github/workflows/
    â””â”€â”€ ci.yml                   # CI/CD pipeline (pytest + flake8)
```

## Running Tests

```bash
# Run all tests with coverage
pytest tests/ -v --cov=app --cov-report=term-missing

# Run specific test
pytest tests/test_vector_store.py -v

# Run linting
flake8 app/ tests/ --max-line-length=120
```

## Deployment

### Docker Deployment

```bash
# Build image
docker build -t endee-rag-demo:latest .

# Run container
docker run -p 8000:8000 \
  -e OPENAI_API_KEY=sk-... \
  -e ENDEE_BASE_URL=http://endee:8080 \
  --network host \
  endee-rag-demo:latest

# Or use docker-compose (includes Endee server)
docker-compose up
```

### Cloud Deployment (Heroku / AWS / GCP)

1. Ensure `.env` variables are set as environment variables
2. Ensure Endee is deployed (use cloud Endee service, or self-hosted)
3. Update `ENDEE_BASE_URL` to point to your cloud Endee endpoint

## Evaluation Criteria âœ“

- âœ… **Forked Endee repository**: Uses https://github.com/endee-io/endee
- âœ… **Vector database integration**: Endee adapters (SDK + HTTP) in `app/vector_store.py`
- âœ… **Practical use case**: RAG/Semantic Search with sample dataset
- âœ… **GitHub hosting**: Ready to push to GitHub
- âœ… **Comprehensive README**: Architecture, setup, API, deployment, and more

## Next Steps

1. **Fork Endee:** https://github.com/endee-io/endee
2. **Clone your fork** and install locally
3. **Configure `.env`** with your OpenAI key and Endee endpoint
4. **Run tests** to verify everything works: `pytest tests/ -v`
5. **Start the server:** `uvicorn app.main:app --reload`
6. **Try the demo:** `python examples/rag_demo.py`
7. **Push to GitHub:** Update the repo link in this README

## Contributing

Contributions are welcome! Please:

1. Fork the project
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the **Apache License 2.0** â€” same as Endee. See [LICENSE](LICENSE) for details.

## Resources

- **Endee Repository:** https://github.com/endee-io/endee
- **Endee Documentation:** https://docs.endee.io
- **OpenAI API:** https://platform.openai.com/docs
- **FastAPI Docs:** https://fastapi.tiangolo.com
- **RAG Overview:** https://en.wikipedia.org/wiki/Retrieval-augmented_generation

## Questions?

Open an issue on GitHub or reach out to the Endee community at https://github.com/endee-io/endee/discussions
